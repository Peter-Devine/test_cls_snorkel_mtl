{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COPA Demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, os\n",
    "from pathlib import Path\n",
    "\n",
    "if not \"cwd\" in globals():\n",
    "   cwd = Path(os.getcwd())\n",
    "sys.path.insert(0, str(cwd.parents[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_NAME = \"ISEAR\"\n",
    "AUX_TASK_NAME = \"SWAG\"\n",
    "BERT_MODEL = \"bert-base-uncased\"\n",
    "\n",
    "dataloader_config = {\n",
    "    \"batch_size\": 16,\n",
    "    \"data_dir\": Path(os.getcwd()).parents[0],\n",
    "    \"splits\": [\"train\", \"dev\"],\n",
    "    \"max_sequence_length\": 60,\n",
    "}\n",
    "\n",
    "trainer_config = {\n",
    "    \"lr\": 2e-4,\n",
    "    \"optimizer\": \"sgd\",\n",
    "    \"n_epochs\": 10,\n",
    "    \"checkpointing\": 1,\n",
    "    \"logging\": 1,\n",
    "    \"grad_clip\": None,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Primary Task from BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloaders import get_dataloaders\n",
    "\n",
    "# Loading primary task data\n",
    "copa_dataloaders = get_dataloaders(\n",
    "    task_name=TASK_NAME,\n",
    "    tokenizer_name=BERT_MODEL,\n",
    "    **dataloader_config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from superglue_tasks import task_funcs\n",
    "\n",
    "# Defining task\n",
    "copa_task = task_funcs[TASK_NAME](BERT_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.classification import MultitaskClassifier\n",
    "from snorkel.classification import Trainer\n",
    "\n",
    "copa_model = MultitaskClassifier(tasks=[copa_task])\n",
    "trainer = Trainer(**trainer_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'ISEAR',\n",
       " 'split': 'valid',\n",
       " 'X_dict': {'token_ids': tensor([[ 101, 4129, 2317,  ...,    0,    0,    0],\n",
       "          [ 101, 2023, 2001,  ...,    0,    0,    0],\n",
       "          [ 101, 1037, 2261,  ..., 2086, 1012, 4445],\n",
       "          ...,\n",
       "          [ 101, 2043, 8218,  ...,    0,    0,    0],\n",
       "          [ 101, 1045, 2018,  ...,    0,    0,    0],\n",
       "          [ 101, 2043, 1045,  ...,    0,    0,    0]]),\n",
       "  'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          ...,\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0],\n",
       "          [0, 0, 0,  ..., 0, 0, 0]]),\n",
       "  'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 1, 1, 1],\n",
       "          ...,\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0],\n",
       "          [1, 1, 1,  ..., 0, 0, 0]])},\n",
       " 'Y_dict': {'ISEAR': tensor([3, 6, 5,  ..., 2, 4, 2])}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(copa_dataloaders[1].dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:: 100%|██████████████████████| 301/301 [03:39<00:00,  5.62s/it, model/all/train/loss=1.83, model/all/train/lr=0.0002, ISEAR/ISEAR/valid/accuracy=0.477]\n",
      "Epoch 1:: 100%|██████████████████████| 301/301 [03:39<00:00,  5.71s/it, model/all/train/loss=1.27, model/all/train/lr=0.0002, ISEAR/ISEAR/valid/accuracy=0.617]\n",
      "Epoch 2:: 100%|█████████████████████| 301/301 [03:40<00:00,  5.88s/it, model/all/train/loss=0.998, model/all/train/lr=0.0002, ISEAR/ISEAR/valid/accuracy=0.667]\n",
      "Epoch 3:: 100%|█████████████████████| 301/301 [03:39<00:00,  5.77s/it, model/all/train/loss=0.861, model/all/train/lr=0.0002, ISEAR/ISEAR/valid/accuracy=0.669]\n",
      "Epoch 4:: 100%|██████████████████████| 301/301 [03:39<00:00,  5.68s/it, model/all/train/loss=0.77, model/all/train/lr=0.0002, ISEAR/ISEAR/valid/accuracy=0.691]\n",
      "Epoch 5:: 100%|█████████████████████| 301/301 [03:41<00:00,  6.05s/it, model/all/train/loss=0.697, model/all/train/lr=0.0002, ISEAR/ISEAR/valid/accuracy=0.699]\n",
      "Epoch 6:: 100%|█████████████████████| 301/301 [03:40<00:00,  5.83s/it, model/all/train/loss=0.611, model/all/train/lr=0.0002, ISEAR/ISEAR/valid/accuracy=0.709]\n",
      "Epoch 7:: 100%|█████████████████████| 301/301 [03:42<00:00,  5.74s/it, model/all/train/loss=0.546, model/all/train/lr=0.0002, ISEAR/ISEAR/valid/accuracy=0.705]\n",
      "Epoch 8:: 100%|██████████████████████| 301/301 [03:42<00:00,  5.93s/it, model/all/train/loss=0.49, model/all/train/lr=0.0002, ISEAR/ISEAR/valid/accuracy=0.692]\n",
      "Epoch 9:: 100%|██████████████████████| 301/301 [03:51<00:00,  6.01s/it, model/all/train/loss=0.42, model/all/train/lr=0.0002, ISEAR/ISEAR/valid/accuracy=0.698]\n"
     ]
    }
   ],
   "source": [
    "# Training on COPA an dsaving model -- takes a long time on CPU!\n",
    "trainer.fit(copa_model, copa_dataloaders)\n",
    "# copa_model.save('best_model_COPA_SuperGLUE_valid_accuracy.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, download and load trained model run ahead of time to save time\n",
    "# ! wget -nc https://www.dropbox.com/s/c7dv5vgr5lqon61/best_model_COPA_SuperGLUE_valid_accuracy.pth\n",
    "# copa_model.load('best_model_COPA_SuperGLUE_valid_accuracy.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#copa_dev_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ISEAR/ISEAR/valid/accuracy': 0.6975}\n"
     ]
    }
   ],
   "source": [
    "# Evaluating model\n",
    "copa_train_loader, copa_dev_loader = copa_dataloaders\n",
    "copa_score = copa_model.score([copa_dev_loader])\n",
    "print(copa_score)\n",
    "#print(f\"COPA (from BERT) Accuracy: {copa_score['COPA/SuperGLUE/valid/accuracy']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Auxiliary Task (SWAG) from BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'D:\\\\Common_Voice\\\\snorkel-superglue\\\\data\\\\Classification_Tasks\\\\SWAG\\\\train.tsv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-60284b64476d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mtask_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mAUX_TASK_NAME\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtokenizer_name\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBERT_MODEL\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[1;33m**\u001b[0m\u001b[0mdataloader_config\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m )\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Common_Voice\\snorkel-superglue\\dataloaders.py\u001b[0m in \u001b[0;36mget_dataloaders\u001b[1;34m(data_dir, task_name, splits, max_data_samples, max_sequence_length, tokenizer_name, batch_size)\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_tokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtokenizer_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0msplit_datasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_label_to_int_dict\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mClassification_Task_Data_Handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_inputs_and_outputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtask_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_len\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_sequence_length\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlanguage_model_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtokenizer_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msplits\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Common_Voice\\snorkel-superglue\\utils\\Classification_Task_Data_Handler.py\u001b[0m in \u001b[0;36mget_inputs_and_outputs\u001b[1;34m(dataset_name, cwd, seq_len, language_model_type)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0msplit\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"dev\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"test\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m         \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjoin_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcwd\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"data\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Classification_Tasks\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msplit\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m\".tsv\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"utf-8\"\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m             \u001b[0mreader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv_reader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"\\t\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\Common_Voice\\\\snorkel-superglue\\\\data\\\\Classification_Tasks\\\\SWAG\\\\train.tsv'"
     ]
    }
   ],
   "source": [
    "# Getting dataloaders, task, and model for SWAG\n",
    "# Note: this is a large dataset—it takes a few minutes to load\n",
    "\n",
    "swag_dataloaders = get_dataloaders(\n",
    "    task_name=AUX_TASK_NAME,\n",
    "    tokenizer_name=BERT_MODEL,\n",
    "    **dataloader_config\n",
    ")\n",
    "\n",
    "swag_task = task_funcs[AUX_TASK_NAME](BERT_MODEL)\n",
    "swag_model = MultitaskModel(tasks=[swag_task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training on SWAG and saving model -- takes a long time on CPU!\n",
    "# trainer.train_model(swag_model, swag_dataloaders)\n",
    "# swag_model.save('./best_model_SWAG_SuperGLUE.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Primary Task from BERT + SWAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "# Initialize COPA model with weights from trained SWAG model\n",
    "copa_swag_model = deepcopy(copa_model)\n",
    "# copa_swag_model.load('best_model_SWAG_SuperGLUE.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from snorkel.mtl.trainer import Trainer\n",
    "\n",
    "# Training on COPA and saving model -- takes a long time on CPU!\n",
    "# trainer.train_model(copa_swag_model, copa_dataloaders)\n",
    "# copa_swag_model.save('best_model_COPA_SWAG_AUX_SuperGLUE_valid_accuracy.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatively, download and load trained model run ahead of time to save time\n",
    "# ! wget -nc https://www.dropbox.com/s/xj2zubij3vqtge5/best_model_COPA_SWAG_AUX_SuperGLUE_valid_accuracy.pth\n",
    "# copa_swag_model.load('best_model_COPA_SWAG_AUX_SuperGLUE_valid_accuracy.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copa_swag_score = copa_swag_model.score(copa_dev_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare performance with/without Aux. Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"COPA (from BERT) Accuracy: {copa_score['COPA/SuperGLUE/valid/accuracy']}\")\n",
    "print(f\"COPA (from BERT + SWAG) Accuracy: {copa_swag_score['COPA/SuperGLUE/valid/accuracy']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor([[1,2,3,4],[6,5,4,3]])[[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
